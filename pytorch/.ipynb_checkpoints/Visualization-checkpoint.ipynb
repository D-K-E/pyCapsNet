{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms, datasets\n",
    "import time, os\n",
    "from torch.autograd import Variable\n",
    "from modules import *\n",
    "\n",
    "from torchvision.utils import make_grid\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def p(s):\n",
    "    print(s)\n",
    "    print('pausing')\n",
    "    time.sleep(10000)\n",
    "\n",
    "class MNIST:\n",
    "    def __init__(self, bs=1):\n",
    "        dataset_transform = transforms.Compose([\n",
    "                       transforms.ToTensor(),\n",
    "                       transforms.Normalize((0.1307,), (0.3081,))\n",
    "                   ])\n",
    "\n",
    "        train_dataset = datasets.MNIST('data', train=True, download=True, transform=dataset_transform)\n",
    "        eval_dataset = datasets.MNIST('data', train=False, download=True, transform=dataset_transform)\n",
    "        \n",
    "        self.train_dataloader  = torch.utils.data.DataLoader(train_dataset, batch_size=bs, shuffle=True)\n",
    "        self.eval_dataloader = torch.utils.data.DataLoader(eval_dataset, batch_size=bs, shuffle=True)\n",
    "\n",
    "bs = 128\n",
    "lr = 1e-3\n",
    "use_cuda = True # False\n",
    "optimizer = 'adam'\n",
    "num_epochs = 100\n",
    "disp_interval = 100\n",
    "save_epoch = 1\n",
    "val_epoch = 1\n",
    "project_id = 'capsnet'\n",
    "num_classes = 10\n",
    "save_dir = 'saved_models'\n",
    "num_epochs = 100\n",
    "\n",
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "\n",
    "mnist = MNIST(bs=bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training started!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/xander/cupyCapsNet/pytorch/modules.py:50: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  c = F.softmax(b)\n",
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:59: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  0][iter    0] loss: 0.7490, acc: 14.0625% (18/128)\n",
      "[epoch  0][iter  100] loss: 0.0012, acc: 95.3125% (122/128)\n",
      "[epoch  0][iter  200] loss: 0.0005, acc: 95.3125% (122/128)\n",
      "[epoch  0][iter  300] loss: 0.0003, acc: 96.8750% (124/128)\n",
      "[epoch  0][iter  400] loss: 0.0001, acc: 97.6562% (125/128)\n",
      "Validating...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/ipykernel_launcher.py:95: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[epoch  0] val acc: 97.8466% (9769/9984)\n",
      "[epoch  1][iter    0] loss: 0.0474, acc: 98.4375% (126/128)\n",
      "[epoch  1][iter  100] loss: 0.0004, acc: 96.8750% (124/128)\n",
      "[epoch  1][iter  200] loss: 0.0002, acc: 96.0938% (123/128)\n",
      "[epoch  1][iter  300] loss: 0.0001, acc: 96.8750% (124/128)\n",
      "[epoch  1][iter  400] loss: 0.0001, acc: 97.6562% (125/128)\n",
      "Validating...\n",
      "[epoch  1] val acc: 98.5276% (9837/9984)\n",
      "[epoch  2][iter    0] loss: 0.0300, acc: 99.2188% (127/128)\n",
      "[epoch  2][iter  100] loss: 0.0003, acc: 97.6562% (125/128)\n",
      "[epoch  2][iter  200] loss: 0.0001, acc: 99.2188% (127/128)\n",
      "[epoch  2][iter  300] loss: 0.0001, acc: 99.2188% (127/128)\n",
      "[epoch  2][iter  400] loss: 0.0001, acc: 98.4375% (126/128)\n",
      "Validating...\n",
      "[epoch  2] val acc: 98.7179% (9856/9984)\n",
      "[epoch  3][iter    0] loss: 0.0252, acc: 97.6562% (125/128)\n",
      "[epoch  3][iter  100] loss: 0.0002, acc: 100.0000% (128/128)\n",
      "[epoch  3][iter  200] loss: 0.0001, acc: 98.4375% (126/128)\n",
      "[epoch  3][iter  300] loss: 0.0001, acc: 98.4375% (126/128)\n",
      "[epoch  3][iter  400] loss: 0.0000, acc: 97.6562% (125/128)\n",
      "Validating...\n",
      "[epoch  3] val acc: 98.8682% (9871/9984)\n",
      "[epoch  4][iter    0] loss: 0.0141, acc: 100.0000% (128/128)\n",
      "[epoch  4][iter  100] loss: 0.0002, acc: 100.0000% (128/128)\n",
      "[epoch  4][iter  200] loss: 0.0001, acc: 98.4375% (126/128)\n",
      "[epoch  4][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  4][iter  400] loss: 0.0000, acc: 99.2188% (127/128)\n",
      "Validating...\n",
      "[epoch  4] val acc: 98.9884% (9883/9984)\n",
      "[epoch  5][iter    0] loss: 0.0192, acc: 98.4375% (126/128)\n",
      "[epoch  5][iter  100] loss: 0.0001, acc: 99.2188% (127/128)\n",
      "[epoch  5][iter  200] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch  5][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  5][iter  400] loss: 0.0000, acc: 99.2188% (127/128)\n",
      "Validating...\n",
      "[epoch  5] val acc: 99.1787% (9902/9984)\n",
      "[epoch  6][iter    0] loss: 0.0122, acc: 100.0000% (128/128)\n",
      "[epoch  6][iter  100] loss: 0.0001, acc: 99.2188% (127/128)\n",
      "[epoch  6][iter  200] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch  6][iter  300] loss: 0.0000, acc: 99.2188% (127/128)\n",
      "[epoch  6][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch  6] val acc: 99.0284% (9887/9984)\n",
      "[epoch  7][iter    0] loss: 0.0144, acc: 100.0000% (128/128)\n",
      "[epoch  7][iter  100] loss: 0.0002, acc: 99.2188% (127/128)\n",
      "[epoch  7][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  7][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  7][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch  7] val acc: 99.1486% (9899/9984)\n",
      "[epoch  8][iter    0] loss: 0.0111, acc: 100.0000% (128/128)\n",
      "[epoch  8][iter  100] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch  8][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  8][iter  300] loss: 0.0000, acc: 99.2188% (127/128)\n",
      "[epoch  8][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch  8] val acc: 99.2388% (9908/9984)\n",
      "[epoch  9][iter    0] loss: 0.0054, acc: 100.0000% (128/128)\n",
      "[epoch  9][iter  100] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch  9][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  9][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch  9][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch  9] val acc: 99.2188% (9906/9984)\n",
      "[epoch 10][iter    0] loss: 0.0091, acc: 99.2188% (127/128)\n",
      "[epoch 10][iter  100] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch 10][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 11][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 11][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 11] val acc: 99.3189% (9916/9984)\n",
      "[epoch 12][iter    0] loss: 0.0026, acc: 100.0000% (128/128)\n",
      "[epoch 12][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 12][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 12][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 12][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 12] val acc: 99.3189% (9916/9984)\n",
      "[epoch 13][iter    0] loss: 0.0054, acc: 100.0000% (128/128)\n",
      "[epoch 13][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 13][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 13][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 13][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 13] val acc: 99.3690% (9921/9984)\n",
      "[epoch 14][iter    0] loss: 0.0072, acc: 100.0000% (128/128)\n",
      "[epoch 14][iter  100] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch 14][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 14][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 14][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 14] val acc: 99.3790% (9922/9984)\n",
      "[epoch 15][iter    0] loss: 0.0059, acc: 100.0000% (128/128)\n",
      "[epoch 15][iter  100] loss: 0.0001, acc: 100.0000% (128/128)\n",
      "[epoch 15][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 15][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 15][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 15] val acc: 99.2588% (9910/9984)\n",
      "[epoch 16][iter    0] loss: 0.0018, acc: 100.0000% (128/128)\n",
      "[epoch 16][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 16][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 16][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 16][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 16] val acc: 99.3089% (9915/9984)\n",
      "[epoch 17][iter    0] loss: 0.0034, acc: 100.0000% (128/128)\n",
      "[epoch 17][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 17][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 17][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 17][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 17] val acc: 99.3289% (9917/9984)\n",
      "[epoch 18][iter    0] loss: 0.0028, acc: 100.0000% (128/128)\n",
      "[epoch 18][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 18][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 18][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 18][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 18] val acc: 99.2488% (9909/9984)\n",
      "[epoch 19][iter    0] loss: 0.0027, acc: 100.0000% (128/128)\n",
      "[epoch 19][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 19][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 19][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 19][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 19] val acc: 99.3590% (9920/9984)\n",
      "[epoch 20][iter    0] loss: 0.0017, acc: 100.0000% (128/128)\n",
      "[epoch 20][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 20][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 20][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 20][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 20] val acc: 99.3189% (9916/9984)\n",
      "[epoch 21][iter    0] loss: 0.0013, acc: 100.0000% (128/128)\n",
      "[epoch 21][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 21][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 21][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 21][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 21] val acc: 99.4091% (9925/9984)\n",
      "[epoch 22][iter    0] loss: 0.0018, acc: 100.0000% (128/128)\n",
      "[epoch 22][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 22][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 22][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 22][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 22] val acc: 99.4191% (9926/9984)\n",
      "[epoch 23][iter    0] loss: 0.0022, acc: 100.0000% (128/128)\n",
      "[epoch 23][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 23][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 23][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 23][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 23] val acc: 99.3389% (9918/9984)\n",
      "[epoch 24][iter    0] loss: 0.0017, acc: 100.0000% (128/128)\n",
      "[epoch 24][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 24][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 24][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 24][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "[epoch 24] val acc: 99.3590% (9920/9984)\n",
      "[epoch 25][iter    0] loss: 0.0018, acc: 100.0000% (128/128)\n",
      "[epoch 25][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 25][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 25][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 25][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 25] val acc: 99.2989% (9914/9984)\n",
      "[epoch 26][iter    0] loss: 0.0015, acc: 100.0000% (128/128)\n",
      "[epoch 26][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 26][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 26][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 26][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 26] val acc: 99.3289% (9917/9984)\n",
      "[epoch 27][iter    0] loss: 0.0011, acc: 100.0000% (128/128)\n",
      "[epoch 27][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 27][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 27][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 27][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 27] val acc: 99.3189% (9916/9984)\n",
      "[epoch 28][iter    0] loss: 0.0007, acc: 100.0000% (128/128)\n",
      "[epoch 28][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 28][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 28][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 28][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 28] val acc: 99.3189% (9916/9984)\n",
      "[epoch 29][iter    0] loss: 0.0008, acc: 100.0000% (128/128)\n",
      "[epoch 29][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 29][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 29][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 29][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 29] val acc: 99.2989% (9914/9984)\n",
      "[epoch 30][iter    0] loss: 0.0009, acc: 100.0000% (128/128)\n",
      "[epoch 30][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 30][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 30][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 30][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 30] val acc: 99.3590% (9920/9984)\n",
      "[epoch 31][iter    0] loss: 0.0005, acc: 100.0000% (128/128)\n",
      "[epoch 31][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 31][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 31][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 31][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 31] val acc: 99.3490% (9919/9984)\n",
      "[epoch 32][iter    0] loss: 0.0010, acc: 100.0000% (128/128)\n",
      "[epoch 32][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 32][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 32][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 32][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 32] val acc: 99.3690% (9921/9984)\n",
      "[epoch 33][iter    0] loss: 0.0006, acc: 100.0000% (128/128)\n",
      "[epoch 33][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 33][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 33][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 33][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 33] val acc: 99.3089% (9915/9984)\n",
      "[epoch 34][iter    0] loss: 0.0008, acc: 100.0000% (128/128)\n",
      "[epoch 34][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 34][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 34][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 34][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 34] val acc: 99.3590% (9920/9984)\n",
      "[epoch 35][iter    0] loss: 0.0007, acc: 100.0000% (128/128)\n",
      "[epoch 35][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 35][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 35][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 35][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 35] val acc: 99.3289% (9917/9984)\n",
      "[epoch 36][iter    0] loss: 0.0006, acc: 100.0000% (128/128)\n",
      "[epoch 36][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 36][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 36][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 36][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 36] val acc: 99.3590% (9920/9984)\n",
      "[epoch 37][iter    0] loss: 0.0006, acc: 100.0000% (128/128)\n",
      "[epoch 37][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 37][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 37][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 37][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 37] val acc: 99.2989% (9914/9984)\n",
      "[epoch 38][iter    0] loss: 0.0007, acc: 100.0000% (128/128)\n",
      "[epoch 38][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 38][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 38][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 38][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 38] val acc: 99.3790% (9922/9984)\n",
      "[epoch 39][iter    0] loss: 0.0006, acc: 100.0000% (128/128)\n",
      "[epoch 39][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 39][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 39][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 39][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 39] val acc: 99.2688% (9911/9984)\n",
      "[epoch 40][iter    0] loss: 0.0005, acc: 100.0000% (128/128)\n",
      "[epoch 40][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 40][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 40][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 40][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 40] val acc: 99.3189% (9916/9984)\n",
      "[epoch 41][iter    0] loss: 0.0005, acc: 100.0000% (128/128)\n",
      "[epoch 41][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 41][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 41][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 41][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 41] val acc: 99.3590% (9920/9984)\n",
      "[epoch 42][iter    0] loss: 0.0004, acc: 100.0000% (128/128)\n",
      "[epoch 42][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 42][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 42][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 42][iter  400] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "Validating...\n",
      "[epoch 42] val acc: 99.3490% (9919/9984)\n",
      "[epoch 43][iter    0] loss: 0.0010, acc: 100.0000% (128/128)\n",
      "[epoch 43][iter  100] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 43][iter  200] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 43][iter  300] loss: 0.0000, acc: 100.0000% (128/128)\n",
      "[epoch 43][iter  400] loss: 0.0000, acc: 10.1562% (13/128)\n",
      "Validating...\n",
      "[epoch 43] val acc: 10.0661% (1005/9984)\n",
      "[epoch 44][iter    0] loss: 0.0004, acc: 7.0312% (9/128)\n",
      "[epoch 44][iter  100] loss: 0.0000, acc: 9.3750% (12/128)\n",
      "[epoch 44][iter  200] loss: 0.0000, acc: 7.0312% (9/128)\n",
      "[epoch 44][iter  300] loss: 0.0000, acc: 10.9375% (14/128)\n",
      "[epoch 44][iter  400] loss: 0.0000, acc: 8.5938% (11/128)\n",
      "Validating...\n",
      "[epoch 44] val acc: 10.1062% (1009/9984)\n",
      "[epoch 45][iter    0] loss: 0.0004, acc: 7.8125% (10/128)\n",
      "[epoch 45][iter  100] loss: 0.0000, acc: 10.9375% (14/128)\n",
      "[epoch 45][iter  200] loss: 0.0000, acc: 10.9375% (14/128)\n",
      "[epoch 45][iter  300] loss: 0.0000, acc: 12.5000% (16/128)\n",
      "[epoch 45][iter  400] loss: 0.0000, acc: 10.9375% (14/128)\n",
      "Validating...\n",
      "[epoch 45] val acc: 10.0761% (1006/9984)\n",
      "[epoch 46][iter    0] loss: 0.0004, acc: 8.5938% (11/128)\n",
      "[epoch 46][iter  100] loss: 0.0000, acc: 12.5000% (16/128)\n",
      "[epoch 46][iter  200] loss: 0.0000, acc: 11.7188% (15/128)\n",
      "[epoch 46][iter  300] loss: 0.0000, acc: 11.7188% (15/128)\n",
      "[epoch 46][iter  400] loss: 0.0000, acc: 11.7188% (15/128)\n",
      "Validating...\n",
      "[epoch 46] val acc: 10.0962% (1008/9984)\n",
      "[epoch 47][iter    0] loss: 0.0004, acc: 13.2812% (17/128)\n",
      "[epoch 47][iter  100] loss: 0.0000, acc: 15.6250% (20/128)\n",
      "[epoch 47][iter  200] loss: 0.0000, acc: 10.1562% (13/128)\n",
      "[epoch 47][iter  300] loss: 0.0000, acc: 6.2500% (8/128)\n",
      "[epoch 47][iter  400] loss: 0.0000, acc: 13.2812% (17/128)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validating...\n",
      "[epoch 47] val acc: 10.0861% (1007/9984)\n",
      "[epoch 48][iter    0] loss: 0.0004, acc: 3.1250% (4/128)\n",
      "[epoch 48][iter  100] loss: 0.0000, acc: 14.0625% (18/128)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-735135fde2d0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m        \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutputs\u001b[0m \u001b[0;34m**\u001b[0m \u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m        \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m        \u001b[0mtrain_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    355\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    356\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 357\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    358\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mhook\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    359\u001b[0m             \u001b[0mhook_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/cupyCapsNet/pytorch/modules.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, scores, labels, reconst, inpt)\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0mnorms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqrt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscores\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    103\u001b[0m         \u001b[0mmargin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.9\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mnorms\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.5\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnorms\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minplace\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 104\u001b[0;31m         \u001b[0mmargin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmargin_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    105\u001b[0m         \u001b[0mreconst_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmse_loss\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreconst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minpt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    106\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmargin_loss\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreconst_factor\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mreconst_loss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # Variables\n",
    "inputs = torch.FloatTensor(1)\n",
    "labels = torch.FloatTensor(1)\n",
    "eye = Variable(torch.eye(num_classes))\n",
    "inputs = Variable(inputs)\n",
    "labels = Variable(labels)\n",
    "\n",
    "# Model\n",
    "model = CapsNet(use_cuda=use_cuda)\n",
    "\n",
    "# cuda\n",
    "if use_cuda:\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    model = model.cuda()\n",
    "    eye = eye.cuda()\n",
    "\n",
    "params = []\n",
    "\n",
    "for key, value in dict(model.named_parameters()).items():\n",
    "    if value.requires_grad:\n",
    "        params += [{'params':[value],'lr':lr}]\n",
    "\n",
    "# optimizer\n",
    "if optimizer == \"adam\":\n",
    "    optimizer = torch.optim.Adam(model.parameters())\n",
    "elif optimizer == \"sgd\":\n",
    "    optimizer = torch.optim.SGD(params)\n",
    "\n",
    "criterion = CapsLoss()\n",
    "\n",
    "print('Training started!')\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    start = time.time()\n",
    "    \n",
    "    # train\n",
    "    model.train()\n",
    "    correct = 0\n",
    "    train_loss = 0\n",
    "    for batch_idx, (imgs, targets) in enumerate(mnist.train_dataloader):\n",
    "        if imgs.size(0) != bs:\n",
    "            continue\n",
    "        targets = torch.eye(num_classes).index_select(dim=0, index=targets)\n",
    "        inputs.data.resize_(imgs.size()).copy_(imgs)\n",
    "        labels.data.resize_(targets.size()).copy_(targets)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs, reconst = model(inputs)\n",
    "        \n",
    "        scores = torch.sqrt((outputs ** 2).sum(2))\n",
    "        loss = criterion(scores, labels, reconst, inputs)\n",
    "        train_loss = loss.data.cpu().numpy()[0]\n",
    "\n",
    "        # backward\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        scores, classes = F.softmax(scores).max(dim=1)\n",
    "        predicted = eye.index_select(dim=0, index=classes.squeeze(1))\n",
    "        \n",
    "        predicted_idx = np.argmax(predicted.data.cpu().numpy(),1)\n",
    "        label_idx = np.argmax(targets.numpy(), 1)\n",
    "        correct = np.sum(predicted_idx == label_idx)\n",
    "        \n",
    "        # info\n",
    "        if batch_idx % disp_interval == 0:\n",
    "            end = time.time()\n",
    "            print(\"[epoch %2d][iter %4d] loss: %.4f, acc: %.4f%% (%d/%d)\" \\\n",
    "                            % (epoch, batch_idx, train_loss/(batch_idx+1), 100.*correct/bs, correct, bs))\n",
    "\n",
    "    save_name = os.path.join(save_dir, '{}_{}.pth'.format(project_id, epoch))\n",
    "    if save_epoch > 0 and batch_idx % save_epoch == 0:\n",
    "        torch.save({\n",
    "          'epoch': epoch,\n",
    "          'state_dict': model.cpu().state_dict(),\n",
    "        }, save_name)\n",
    "    if use_cuda:\n",
    "        model.cuda()\n",
    "\n",
    "    # val\n",
    "    if epoch % val_epoch == 0:\n",
    "        print('Validating...')\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        model.eval()\n",
    "        for batch_idx, (imgs, targets) in enumerate(mnist.eval_dataloader):\n",
    "            if imgs.size(0) != bs:\n",
    "                continue\n",
    "            targets = torch.eye(num_classes).index_select(dim=0, index=targets)\n",
    "            inputs.data.resize_(imgs.size()).copy_(imgs)\n",
    "            labels.data.resize_(targets.size()).copy_(targets)\n",
    "            \n",
    "            outputs, reconst = model(inputs)\n",
    "            scores = torch.sqrt((outputs ** 2).sum(2))\n",
    "            scores, classes = F.softmax(scores).max(dim=1)\n",
    "            predicted = eye.index_select(dim=0, index=classes.squeeze(1))\n",
    "        \n",
    "            predicted_idx = np.argmax(predicted.data.cpu().numpy(),1)\n",
    "            label_idx = np.argmax(targets.numpy(), 1)\n",
    "            correct += np.sum(predicted_idx == label_idx)\n",
    "            total += targets.size(0)\n",
    "        print(\"[epoch %2d] val acc: %.4f%% (%d/%d)\" \\\n",
    "                                % (epoch, 100.*correct/total, correct, total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-8dc1f5e04fc2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0meye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "## Visualization\n",
    " # Variables\n",
    "inputs = torch.FloatTensor(1)\n",
    "labels = torch.FloatTensor(1)\n",
    "eye = Variable(torch.eye(num_classes))\n",
    "inputs = Variable(inputs)\n",
    "labels = Variable(labels)\n",
    "\n",
    "model_path = 'saved_models/capsnet_42.pth'\n",
    "# Model\n",
    "model = CapsNet(use_cuda=use_cuda)\n",
    "model.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "# cuda\n",
    "if use_cuda:\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    model = model.cuda()\n",
    "    eye = eye.cuda()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# get eval output\n",
    "model.eval()\n",
    "correct = 0\n",
    "train_loss = 0\n",
    "imgs, targets = next(iter(mnist.eval_dataloader))\n",
    "\n",
    "inputs.data.resize_(imgs.size()).copy_(imgs)\n",
    "\n",
    "outputs, reconst = model(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'reconst' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-4-24353ef41081>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     14\u001b[0m     \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 16\u001b[0;31m \u001b[0mshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreconst\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'reconst' is not defined"
     ]
    }
   ],
   "source": [
    "def show(inputs, reconst, bs):\n",
    "    \n",
    "    orig = inputs.data.cpu().view(bs, -1)\n",
    "    orig -= orig.min(dim=1, keepdim=True)[0]\n",
    "    orig /= orig.max(dim=1, keepdim=True)[0]\n",
    "    disp = torch.cat([orig.view(bs, 1, 28, 28), reconst.data.cpu().view(bs, 1, 28, 28)], dim=3)\n",
    "    \n",
    "    img = make_grid(disp, padding=5)\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "#     fig, ax = subplots(figsize=(18, 18))\n",
    "    plt.figure(figsize = (18,18))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()\n",
    "\n",
    "show(inputs, reconst, bs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-c24a5da5b988>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mitertools\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mproduct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0minpt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mrecon\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mreconst\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcpu\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/torch/tensor.py\u001b[0m in \u001b[0;36mdata\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    405\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mRuntimeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m     \u001b[0;31m# Numpy array interface, to support `numpy.asarray(tensor) -> ndarray`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cannot call .data on a torch.Tensor: did you intend to use autograd.Variable?"
     ]
    }
   ],
   "source": [
    "import matplotlib.gridspec as gridspec\n",
    "from itertools import product\n",
    "\n",
    "inpt = inputs.data.cpu().numpy()\n",
    "recon = reconst.data.cpu().view(bs, 1, 28, 28).numpy()\n",
    "\n",
    "def compare_reconst(inputs, recons, bs):\n",
    "    # inputs, recons both have size (bs, 1, 28, 28)\n",
    "    # bs is the batchsize\n",
    "    \n",
    "    fig = plt.figure(figsize=(18, 18))\n",
    "\n",
    "    # gridspec inside gridspec\n",
    "    outer_grid = gridspec.GridSpec(bs // 8, 8, wspace=0.2, hspace=0.2)\n",
    "\n",
    "    for i in range(bs):\n",
    "        inner_grid = gridspec.GridSpecFromSubplotSpec(1, 2,\n",
    "                subplot_spec=outer_grid[i], wspace=0.2, hspace=0.2)\n",
    "        ax1 = plt.Subplot(fig, inner_grid[0])\n",
    "        ax1.imshow(inputs[i].squeeze())\n",
    "        ax1.set_xticks([])\n",
    "        ax1.set_yticks([])\n",
    "        fig.add_subplot(ax1)\n",
    "        ax2 = plt.Subplot(fig, inner_grid[1])\n",
    "        ax2.imshow(recons[i].squeeze())\n",
    "        ax2.set_xticks([])\n",
    "        ax2.set_yticks([])\n",
    "        fig.add_subplot(ax2)\n",
    "\n",
    "    all_axes = fig.get_axes()\n",
    "\n",
    "    #show only the outside spines\n",
    "    for ax in all_axes:\n",
    "        for sp in ax.spines.values():\n",
    "            sp.set_visible(False)\n",
    "\n",
    "    plt.show()\n",
    "    \n",
    "# compare_reconst(inpt, recon, 128) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'num_classes' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-f162671f062c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mFloatTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0meye\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0meye\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0minputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mlabels\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mVariable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'num_classes' is not defined"
     ]
    }
   ],
   "source": [
    "## Visualization\n",
    " # Variables\n",
    "inputs = torch.FloatTensor(1)\n",
    "labels = torch.FloatTensor(1)\n",
    "eye = Variable(torch.eye(num_classes))\n",
    "inputs = Variable(inputs)\n",
    "labels = Variable(labels)\n",
    "\n",
    "model_path = 'saved_models/capsnet_42.pth'\n",
    "# Model\n",
    "model = CapsNet(use_cuda=use_cuda)\n",
    "model.load_state_dict(torch.load(model_path)['state_dict'])\n",
    "decoder = model.decoder\n",
    "\n",
    "# cuda\n",
    "if use_cuda:\n",
    "    inputs = inputs.cuda()\n",
    "    labels = labels.cuda()\n",
    "    model = model.cuda()\n",
    "    eye = eye.cuda()\n",
    "\n",
    "start = time.time()\n",
    "\n",
    "# get eval output\n",
    "model.eval()\n",
    "correct = 0\n",
    "train_loss = 0\n",
    "imgs, targets = next(iter(mnist.eval_dataloader))\n",
    "img = imgs[0].unsqueeze(0)\n",
    "target = targets[0]\n",
    "print(target)\n",
    "inputs.data.resize_(img.size()).copy_(img)\n",
    "mask = torch.zeros((1,10,16,1))\n",
    "mask[:, target, :, :] = 1\n",
    "mask = Variable(mask)\n",
    "if use_cuda:\n",
    "    mask = mask.cuda()\n",
    "    \n",
    "outputs, reconst = model(inputs)\n",
    "\n",
    "show(inputs, reconst, 1)\n",
    "\n",
    "digit_repr = outputs  * mask\n",
    "\n",
    "recons = []\n",
    "for dim in range(16):\n",
    "    for perturb in np.arange(-0.25,0.25,0.05):\n",
    "        p_mat = torch.zeros((1,10,16,1))\n",
    "        p_mat[:, target, dim, :] = perturb\n",
    "        p_mat = Variable(p_mat)\n",
    "#         print(p_mat)\n",
    "        if use_cuda:\n",
    "            p_mat = p_mat.cuda()\n",
    "        _recon = decoder(digit_repr + p_mat)\n",
    "        recons.append(_recon)\n",
    "recons = torch.cat(recons, dim=0)\n",
    "recons = recons.view(160, 1, 28, 28)\n",
    "\n",
    "def show_interp(recons):\n",
    "    \n",
    "    img = make_grid(recons, nrow=10, padding=5)\n",
    "    \n",
    "    npimg = img.numpy()\n",
    "#     fig, ax = subplots(figsize=(18, 18))\n",
    "    plt.figure(figsize = (18,18))\n",
    "    plt.imshow(np.transpose(npimg, (1,2,0)), interpolation='nearest')\n",
    "    plt.show()\n",
    "    \n",
    "print(recons.size())\n",
    "show_interp(recons.data.cpu())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
